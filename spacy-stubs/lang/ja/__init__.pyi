from ...language import Language
from ...util import DummyTokenizer
from collections import namedtuple
from typing import Any, Optional

DummyNode = namedtuple('DummyNode', ['surface', 'pos', 'feature'])

DummyNodeFeatures = namedtuple('DummyNodeFeatures', ['lemma'])

class JapaneseTokenizer(DummyTokenizer):
    vocab: Any = ...
    tokenizer: Any = ...
    def __init__(self, cls: Any, nlp: Optional[Any] = ...) -> None: ...
    def __call__(self, text: Any): ...

class JapaneseDefaults(Language.Defaults):
    lex_attr_getters: Any = ...
    stop_words: Any = ...
    tag_map: Any = ...
    writing_system: Any = ...
    @classmethod
    def create_tokenizer(cls, nlp: Optional[Any] = ...): ...

class Japanese(Language):
    lang: str = ...
    Defaults: Any = ...
    def make_doc(self, text: Any): ...
