from . import util as util
from .attrs import ID as ID, LOWER as LOWER, NORM as NORM, ORTH as ORTH, PREFIX as PREFIX, SHAPE as SHAPE, SUFFIX as SUFFIX
from .errors import Errors as Errors, Warnings as Warnings, user_warning as user_warning
from thinc.v2v import Affine, Model
from typing import Any, Optional

VECTORS_KEY: str
USE_MODEL_REGISTRY_TOK2VEC: bool

def cosine(vec1: Any, vec2: Any): ...
def create_default_optimizer(ops: Any, **cfg: Any): ...
def with_cpu(ops: Any, model: Any): ...

class extract_ngrams(Model):
    ngram_size: Any = ...
    attr: Any = ...
    def __init__(self, ngram_size: Any, attr: Any = ...) -> None: ...
    def begin_update(self, docs: Any, drop: float = ...): ...

class PrecomputableAffine(Model):
    nO: Any = ...
    nP: Any = ...
    nI: Any = ...
    nF: Any = ...
    def __init__(self, nO: Optional[Any] = ..., nI: Optional[Any] = ..., nF: Optional[Any] = ..., nP: Optional[Any] = ..., **kwargs: Any) -> None: ...
    def begin_update(self, X: Any, drop: float = ...): ...
    @staticmethod
    def init_weights(model: Any): ...

def link_vectors_to_models(vocab: Any) -> None: ...
def PyTorchBiLSTM(nO: Any, nI: Any, depth: Any, dropout: float = ...): ...
def Tok2Vec(width: Any, embed_size: Any, **kwargs: Any): ...
def reapply(layer: Any, n_times: Any): ...
def asarray(ops: Any, dtype: Any): ...
def get_col(idx: Any): ...
def doc2feats(cols: Optional[Any] = ...): ...
def print_shape(prefix: Any): ...
def get_token_vectors(tokens_attrs_vectors: Any, drop: float = ...): ...
def logistic(X: Any, drop: float = ...): ...
def zero_init(model: Any): ...
def getitem(i: Any): ...

class MultiSoftmax(Affine):
    name: str = ...
    out_sizes: Any = ...
    nO: Any = ...
    nI: Any = ...
    def __init__(self, out_sizes: Any, nI: Optional[Any] = ..., **kwargs: Any) -> None: ...
    def predict(self, input__BI: Any): ...
    def begin_update(self, input__BI: Any, drop: float = ...): ...

def build_tagger_model(nr_class: Any, **cfg: Any): ...
def build_morphologizer_model(class_nums: Any, **cfg: Any): ...
def SpacyVectors(docs: Any, drop: float = ...): ...
def build_text_classifier(nr_class: Any, width: int = ..., **cfg: Any): ...
def build_bow_text_classifier(nr_class: Any, ngram_size: int = ..., exclusive_classes: bool = ..., no_output_layer: bool = ..., **cfg: Any): ...
def cpu_softmax(X: Any, drop: float = ...): ...
def build_simple_cnn_text_classifier(tok2vec: Any, nr_class: Any, exclusive_classes: bool = ..., **cfg: Any): ...
def build_nel_encoder(embed_width: Any, hidden_width: Any, ner_types: Any, **cfg: Any): ...
def flatten(seqs: Any, drop: float = ...): ...
def concatenate_lists(*layers: Any, **kwargs: Any): ...
def masked_language_model(vocab: Any, model: Any, mask_prob: float = ...): ...

class _RandomWords:
    words: Any = ...
    probs: Any = ...
    def __init__(self, vocab: Any) -> None: ...
    def next(self): ...

class CharacterEmbed(Model):
    nM: Any = ...
    nC: Any = ...
    def __init__(self, nM: Optional[Any] = ..., nC: Optional[Any] = ..., **kwargs: Any) -> None: ...
    @property
    def nO(self): ...
    @property
    def nV(self): ...
    def begin_update(self, docs: Any, drop: float = ...): ...

def get_cossim_loss(yh: Any, y: Any, ignore_zeros: bool = ...): ...
